//working directory for temporary/intermediate files produced in the workflow processes
workDir = "$HOME/temp" 

//global parameters
params {
    // general options
    sample_sheet                = "test_data/sra_sample_sheet.csv"
    download_sra_fqs            = true
    //validate_params           = true // will add in the sample sheet validation
    queue                       = 'sceaq'
    project                     = '207f23bf-acb6-4835-8bfe-142436acb58c'
    outdir                      = "./test_output/"
    publish_dir_mode            = 'copy'

    //star specific params
    // Must be full filepaths for files outside the projectDir
    index                       = '/gpfs/shared_data/STAR/human_v38/STAR_2.7'
    build_index                 = false
    gtf                         = '/gpfs/shared_data/STAR/human_v38/STAR_2.7/genes.gtf'
    fasta                       = '/gpfs/shared_data/STAR/human_v38/STAR_2.7/genome.fa'
    star_ignore_sjdbgtf         = false
    seq_platform                = ''
    seq_center                  = ''

    //trimgalore module specific parameters
    trim                        = false
    clip_r1                     = 0
    clip_r2                     = 0
    three_prime_clip_r1         = 0
    three_prime_clip_r2         = 0

    //RSEQC specific parameters
    gene_list                   = '/gpfs/shared_data/rseqc/hg38_rRNA.bed'
    ref_gene_model              = '/gpfs/shared_data/rseqc/hg38_GENCODE.v38.bed'

    //fasterq-dump params
    user_settings               = './ncbi-user-settings.mkfg'
}

// Computational resource allocation for the processes run in the workflow
process {
    publishDir = [
        path: { "${params.outdir}/${task.process.tokenize(':')[-1].tokenize('_')[0].toLowerCase()}" },
        mode: params.publish_dir_mode,
        saveAs: { filename -> filename.equals('versions.yml') ? null : filename }
    ]
    errorStrategy = "retry"
    maxRetries = 2

    //STAR-aligner process specific parameters
    //https://www.nextflow.io/docs/latest/process.html#dynamic-computing-resources
    withName: STAR_ALIGN {
        cpus = { 4 * task.attempt }
        memory = { 32.GB * task.attempt }
        ext.args = '--readFilesCommand "gunzip -c"'
    }

    //STAR index process specific parameters
    withName: STAR_GENOMEGENERATE {
        cpus = { 8 * task.attempt }
        memory = { 64.GB * task.attempt }
        ext.args = ''
    }

    //Trimgalore process specific parameters
    withName: TRIMGALORE {
        cpus = { 2 * task.attempt }
        memory = { 8.GB * task.attempt }
        ext.args = ''
    }

    //FastQC process specific parameters
    withName: FASTQC {
        cpus = 1
        memory = 8.GB
        ext.args = '--quiet'
    }
    
    //RSEQC process params
    withLabel: RSEQC {
        cpus = { 1 * task.attempt }
        memory = { 8 * task.attempt }
        ext.args = ''
    }

    //RSEQC process params
    withName: RSEQC_TIN {
        cpus = { 1 * task.attempt }
        memory = { 8 * task.attempt }
        ext.args = ''
    }

    //MULTIQC process specific parameters
    withName: MULTIQC {
        cpus = 1
        memory = 8.GB
        ext.args = '--module fastqc --module star --module rseqc'
    }

    //SRA process specific parameters
    withName: SRATOOLS_FASTERQDUMP {
        cpus = 1
        memory = 8.GB
        ext.args = '--verbose'
        ext.args2 = '--verbose'
    }
}

//Create profiles to easily switch between the different process executors and platforms.
params.enable_conda=false //Using the profile "PBS_conda" will set this to true, otherwise it should be false
profiles {
    //For running on an interactive session on cybertron with singularity module loaded
    local_singularity {
        process.executor = 'local'
        singularity.enabled = true
    }
    //For executing the jobs on the HPC cluster with singularity containers
    PBS_singularity {
        process.executor = 'pbspro' 
        process.queue = "${params.queue}"
        process.clusterOptions = "-P ${params.project}"
        //process.clusterOptions = "-P \$(project code ${params.project})" //renders correctly in command.run script but scheduler won't accept it.
        process.beforeScript = 'module load singularity' //parameterize the module version with params.SINGULARITY in main_run.sh
        singularity.enabled = true //need some logic here to switch to false if conda used
    }
    //For executing the jobs on the HPC cluster with conda environments. 
    PBS_conda {
        process.executor = 'pbspro' 
        process.queue = "${params.queue}"
        process.clusterOptions = "-P ${params.project}"
        params.enable_conda = true
    }
    //For running interactively on local macbook with docker installed. 
    local_docker {
        process.executor = 'local'
        docker.enabled = true
    }
}

//Configs for singularity containers on cybertron
singularity {
    autoMounts = true
    cacheDir = "$HOME/singularity"
    runOptions = '--containall --no-home'
}

//Use personal conda environments on cybertron if params.conda_enabled = true
conda {
    cacheDir = "$HOME/miniconda3/envs/"
}

//Configs for docker containers on local macbook with M1 chip with 64Gb memory
docker {
    temp = 'auto'
    runOptions = "--platform linux/amd64 --memory=32g --cpus=0.000"
}

//overwrite reports when the workflow is executed again 
report {
    overwrite = true
}