---
title: "T-ALL Bulk RNA-seq STAR Quantification"
author: "Jenny L. Smith"
jupyter: python3
execute: 
  enabled: true
  cache: true
  freeze: auto
format:
  html:
    quarto-required: ">=1.6.40"
    theme: cyborg
    toc: true
    toc-depth: 3
    toc-location: left-body
    code-fold: false
    code-overflow: wrap
    code-line-numbers: false
    code-link: true
    code-copy: true
    anchor-sections: true
    fontsize: 1.1em
    linestretch: 1.5
    smooth-scroll: true
    email-obfuscation: javascript
---

# Set-up 

```{python}
# Core plotting libraries
import numpy as np
import matplotlib.pyplot as plt

# Session information
import session_info
```

```{r}
library(biomaRt)
library(dplyr)
library(stringr)
library(purrr)
library(tidyr)
```

# Background

please see attached list of the samples we sequenced with the following info:
  - [...]


### Collaborators

- [NAME 1]
- [NAME 2]
- [...]

- Department of Pediatric Hematology-Oncology, and Cell and Gene Therapies

- Bambino Ges√π Children's Hospital

# Install Dependencies

Use the lab quarto template 
```{bash}
quarto use template Meshinchi-Lab/py_analysis_template
python3 -m venv venv 
source venv/bin/activate 
python3 -m pip install -r requirements.txt
```

Install nextflow and NF-Core tools CLI 
```{bash}
python3 -m pip install nextflow
python3 -m pip install nf-core
```

# Download and Prepare Reference Data

```{bash}
# URL='https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_48/GRCh38.primary_assembly.genome.fa.gz'

REFS="/genome_references/human/gencode_v48/"
sudo mkdir -p $REFS

rclone lsd --http-url https://ftp.ebi.ac.uk :http:/pub/databases/gencode/Gencode_human/release_48

cd $REFS
sudo rclone copy --http-url https://ftp.ebi.ac.uk :http:/pub/databases/gencode/Gencode_human/release_48/GRCh38.primary_assembly.genome.fa.gz . -P
```

```{r}
species <- "Homo_sapiens"
# https://www.gencodegenes.org/human/releases.html
# gencode v48 corresponds to ensembl v114
mart <- useEnsembl('ensembl', 
                   dataset = 'hsapiens_gene_ensembl', 
                   version = 114)
# list attributes 
mart_attr <- listAttributes(mart)
mart_filt <- listFilters(mart, what = c("name",
                                        "description",
                                        "fullDescription",
                                        "options"))

head(mart_attr)
head(mart_filt)

# Biotypes available 

# artifact,IG_C_gene,IG_C_pseudogene,IG_D_gene,IG_J_gene,IG_J_pseudogene,IG_pseudogene,IG_V_gene,IG_V_pseudogene,lncRNA,miRNA,misc_RNA,Mt_rRNA,Mt_tRNA,nonsense_mediated_decay,non_stop_decay,processed_pseudogene,processed_transcript,protein_coding,protein_coding_CDS_not_defined,protein_coding_LoF,pseudogene,retained_intron,ribozyme,rRNA,rRNA_pseudogene,scaRNA,snoRNA,snRNA,sRNA,TEC,transcribed_processed_pseudogene,transcribed_unitary_pseudogene,transcribed_unprocessed_pseudogene,translated_processed_pseudogene,TR_C_gene,TR_D_gene,TR_J_gene,TR_J_pseudogene,TR_V_gene,TR_V_pseudogene,unitary_pseudogene,unprocessed_pseudogene,vault_RNA
```

```{r}
rRNAs <- biomaRt::getBM(values=c("rRNA", "rRNA_pseudogene","Mt_rRNA","ribozyme"),
               filters="biotype", 
               attributes=c("chromosome_name","exon_chrom_start",
                            "exon_chrom_end","strand","ensembl_transcript_id",
                            "ensembl_exon_id","external_gene_name",
                            "gene_biotype","description"), 
               mart = mart)

head(rRNAs)
# table(rRNAs$strand)
dim(rRNAs) #589   

rRNAs_df <- rRNAs %>% 
  mutate(strand = ifelse(strand == 1, "+", "-"),
         start = exon_chrom_start,
         end = exon_chrom_end,
         score = 0,
         itemRgb = 0,
         blockCount = 1,
         blockSizes = exon_chrom_end - exon_chrom_start,
         blockStarts = 0) %>% 
  select(chromosome_name:exon_chrom_end,
         ensembl_exon_id,
         score, 
         strand,
         start,
         end,
         itemRgb,
         blockCount,
         blockSizes,
         blockStarts)

head(rRNAs_df)
dim(rRNAs_df)
# View(rRNAs)
```

```{r}
dir.create("data/references/human/", recursive = TRUE)
write.table(select(rRNAs, ensembl_transcript_id),
            file = "data/references/human/ensembl_transcript_id_v114.txt",
            sep = "\t", 
            quote = FALSE, 
            col.names = FALSE,
            row.names = FALSE)
```

```{bash}
sudo cp data/references/human/ensembl_transcript_id_v114.txt /genome_references/human/GRCh38/rRNA/ensembl_transcript_id_v114.txt
```

# Download Test Datasets

Human data from the NF-Core github repo 

```{bash}
# https://github.com/nf-core/test-datasets/tree/rnafusion/testdata/human

sudo wget -v https://raw.githubusercontent.com/nf-core/test-datasets/refs/heads/rnafusion/testdata/human/README.md

sudo wget -v https://github.com/nf-core/test-datasets/raw/refs/heads/rnafusion/testdata/human/reads_1.fq.gz

sudo wget -v https://github.com/nf-core/test-datasets/raw/refs/heads/rnafusion/testdata/human/reads_2.fq.gz
```

# Run Test Data

### Set-up environment 

```{bash}
# colima
cd ~/opt
curl -LO https://github.com/abiosoft/colima/releases/latest/download/colima-$(uname)-$(uname -m)
sudo install colima-$(uname)-$(uname -m) /usr/local/bin/colima

# lima
cd ~/opt
wget https://github.com/lima-vm/lima/releases/download/v1.1.1/lima-1.1.1-Linux-x86_64.tar.gz
tar -xvzf lima-1.1.1-Linux-x86_64.tar.gz

# qemu 1
sudo apt-get install qemu-system


# configure the docker engine
URL="https://download.docker.com/linux/ubuntu/dists/jammy/pool/stable/amd64"
wget $URL/containerd.io_1.7.27-1_amd64.deb
wget $URL/docker-ce-cli_28.3.1-1~ubuntu.22.04~jammy_amd64.deb
wget $URL/docker-ce_28.3.1-1~ubuntu.22.04~jammy_amd64.deb

sudo dpkg --log=containerd.log --debug=10 -i containerd.io_1.7.27-1_amd64.deb && \
sudo dpkg --log=docker-ce-cli.log --debug=10 -i docker-ce-cli_28.3.1-1~ubuntu.22.04~jammy_amd64.deb && \
sudo dpkg --log=docker-ce-cli.log --debug=10 -i docker-ce_28.3.1-1~ubuntu.22.04~jammy_amd64.deb
```

Configure the `docker` user group

```{bash}
#https://docs.docker.com/engine/install/linux-postinstall/
sudo groupadd docker
sudo usermod -aG docker $USER
newgrp docker
docker run hello-world
```

```{bash}
# activate venv
source venv/bin/activate
./main_run test_pe_dataset
```

getent group docker
id -u
id -g
id -G


# Run T-ALL Samples 

```{bash}
SOURCE="$HOME/mnt/opbg/ngsonco/NGS/Francesca Benini/T-ALL/WTS run 2025.05.12/WTS_1-51-38360350"
TARGET="$HOME/github_repos/2025.06.02_RNAseq_Bulk_T-ALL/data/fastq/WTS_run_2025.05.12"

# symlink the fastqs from the network drive to the bioinformatics PC
ln -s "$SOURCE" $TARGET
```

```{bash}
# create an output directory for the rna-seq counts 
OUTDIR="$HOME/github_repos/2025.06.02_RNAseq_Bulk_T-ALL/data/rnaseq_quant"
mkdir $OUTDIR
```

# Sample Metadata

```{r}
sample_info <- read.table(file.path(Sys.getenv("HOME"),"github_repos/2025.06.02_RNAseq_Bulk_T-ALL/data/metadata/2025.06.03_T-ALL_samples_forJenny_rnaseq_libraries_cleaned.tsv"),
                          sep = "\t",
                          header = TRUE)


head(sample_info)
dim(sample_info)
```

## Concatenate Fastq Files 

```{r}
# list the fastq files for each sample/lane
fqs_path <- file.path(Sys.getenv("HOME"), "github_repos/2025.06.02_RNAseq_Bulk_T-ALL/data/fastq/WTS_run_2025.05.12")

if ( ! file.exists("fastq_filepaths.txt")){
 fqs_dir <- dir(fqs_path, 
               recursive = TRUE,
               full.names = TRUE,
               pattern = "*.fastq.gz") %>%
               as.data.frame()
  write.delim(fqs_dir, "fastq_filepaths.txt", sep="\t", col.names = FALSE, row.names = FALSE)
}

fqs_dir <- read.delim("fastq_filepaths.txt", header=FALSE)
fqs_dir <- fqs_dir[["V1"]]
head(fqs_dir)
length(fqs_dir) #204
```

```{r}
# define outdirs
OUTDIR="/mnt/bioinformatics/nextflow_out/2025.06.02_RNAseq_Bulk_T-ALL/fastq"
PROJ_DATA_DIR <- file.path(Sys.getenv("HOME"), "github_repos/2025.06.02_RNAseq_Bulk_T-ALL/data/fastq/concatenated")
dir.create(PROJ_DATA_DIR, recursive = TRUE)

# concatenate Lane 1 and Lane 2 for all samples
fqs_concat<- map_dfr(.x = fqs_dir, .f = ~ t(str_split_1(.x, pattern = "/")) %>% 
    as.data.frame()) %>% 
    select(-V1) 

fqs_concat <- fqs_concat %>% 
    rename_all(.funs = ~ unlist(fqs_concat[1,]))  %>% 
    mutate(fastq_path = fqs_dir,
           single_end = "false",
           library_chemistry = "Illumina Stranded Total RNA Prep, Ligation with Ribo-Zero Plus") %>% 
    select(-c(home:github_repos, data),
            project = `2025.06.02_RNAseq_Bulk_T-ALL`,
            type = fastq,
            run_name = WTS_run_2025.05.12,
            fastq_generation = `FASTQ_Generation_2025-05-15_14_48_36Z-60284247`,
            lane = `47_L002-ds.f8598a51d9c442ffb20db6d63e4e182d`,
            fastq_file = `6728_S47_L002_R1_001.fastq.gz`,
            fastq_path) %>% 
    mutate(sample_number = str_split_fixed(lane, pattern = "_", n = 2)[,1],
           lane = str_split_fixed(lane, pattern = "[_-]", n = 3)[,2], 
           sample_name = str_split_fixed(fastq_file, pattern = "_", n = 2)[,1],
           read = str_split_fixed(fastq_file, pattern = "_", n = 5)[,4],
           sample_id = gsub("^(.+)_L.+001.+$", "\\1", fastq_file)) %>% 
    select(sample_id, 
           sample_name, 
           lane, 
           read, 
           fastq_file, 
           everything()) %>% 
    arrange(desc(sample_id), read, lane) %>% 
    group_by(sample_id, sample_name, read) %>%
    mutate(concatenated_fastq = glue::glue("{OUTDIR}/{sample_id}_{read}_001.fastq"),
           concatenated_fastq_path = glue::glue("{OUTDIR}/{sample_id}_{read}_001.fastq.gz")) %>%
    mutate(cat_command = glue::glue("echo 'Processing {sample_id}_{read}'\nzcat {paste(fastq_path, collapse = ' ')} > {concatenated_fastq} && gzip -v {concatenated_fastq} & \n") %>%
               unique() %>% 
               c(.,"")) %>%
    ungroup() %>%
    select(-concatenated_fastq)

head(fqs_concat)
# dim(fqs_concat) #204  12
# length(unique(fqs_concat$sample_name)) #51

write.table(fqs_concat, 
            file = "data/2025.06.02_RNAseq_Bulk_T-ALL_fastq_manifest.tsv",
            sep = "\t")
```

```{bash}
# Use the partition in /mnt with ~4tb of disk space
OUTDIR="/mnt/bioinformatics/nextflow_out/2025.06.02_RNAseq_Bulk_T-ALL/fastq"
# make a symlink to the data analysis directory
PROJ_DATA_DIR="$HOME/github_repos/2025.06.02_RNAseq_Bulk_T-ALL/data/fastq/concatenated"

ln -s $OUTDIR $PROJ_DATA_DIR
```

```{r}
PROJ_DATA_DIR <- file.path(Sys.getenv("HOME"), "github_repos/2025.06.02_RNAseq_Bulk_T-ALL/data/fastq/concatenated")

# create a single shell script to concatenate Lane 1 and Lane 2 fastqs for each sample
cmds <- fqs_concat[["cat_command"]] %>% 
    grep("^$", ., invert = TRUE, value = TRUE)

length(cmds) #102

# split into two shell scripts to have a small initial sample size of N=3 to estimate necessary computational resources
cmds_list <- map(1:2, .f = function(i, all_cmds = cmds){
  if (i == 1){
    index <- 1:6
  }else{
    index <- 7:length(all_cmds)
  }
  cmd_string <- all_cmds[index] %>%
    paste(., collapse = "\n") %>% 
    glue::glue("#!/bin/bash\n\n",
          "# uncompress and concatentate fastq files from lane 1 and lane 2\n",
           "{cmds}\n",
           "wait\n\n",
           cmds = .)
  
  # write the shell scripts to a file in the analysis directory
  outfile <- paste0("concat_fqs_v",i,".sh")
  cat(cmd_string, file = file.path(dirname(PROJ_DATA_DIR),outfile))

  # return the string
  cmd_string
})

# head(cmds)
str_count(string = cmds_list[[1]], pattern = "zcat") # 6
str_count(string = cmds_list[[2]], pattern = "zcat") # 6
```

```{bash, eval=FALSE}
# define variables
FQS_DIR="$HOME/github_repos/2025.06.02_RNAseq_Bulk_T-ALL/data/fastq"
SCRIPT="$FQS_DIR/concat_fqs_v1.sh"
LOG="$FQS_DIR/concatenation_v1.log"

# Run the concatenation script. save stdout and stderr to log file
bash $SCRIPT >> $LOG 2>&1
```


## Sample Sheet 

```{r}
DESCRIPTION_HEADER <- c("# column r1 : the absolute or relative filepath for the read 1 fastq in paired-end RNA-seq, or the single-end fastq file.
# column r2 : the absolute or relative filepath for the read 2 fastq in paired-end RNA-seq.
# column id : unique sample ID, no duplicates allowed in the sample sheet.
# column single_end : boolean [true/false] if the data is single-end or paired-end.
id,r1,r2,single_end")
```

```{r}
SAMPLE_SHEET <- "data/sample_sheets/2025.06.03_T-ALL_bulk_rnaseq_sample_sheet_"
V1 <- paste0(SAMPLE_SHEET, "v1.csv")
V2 <- paste0(SAMPLE_SHEET,"v2.csv")

cat(DESCRIPTION_HEADER, file = V1, sep = "\n")
cat(DESCRIPTION_HEADER, file = V2, sep = "\n")

sample_sheet <- fqs_concat %>% 
  select(id = sample_id,
          read,
          single_end,
          concatenated_fastq_path) %>% 
  distinct() %>% 
  pivot_wider(id_cols = c(id, single_end),
              names_from = read,
              values_from = concatenated_fastq_path) %>% 
  janitor::clean_names()
              

head(sample_sheet)
dim(sample_sheet)

for (i in 1:2) {
  outfile <- paste0("V",i)
  if (i == 1){
    index <- c(1:3)
  }else{
    index <- c(4:51)
  }

  sample_sheet[index,] %>% 
    glue::glue_data("{id},{r1},{r2},{single_end}")  %>% 
    cat(.,  file = get(outfile), sep = "\n", append = TRUE)

}
```

```{bash}
NXF_OUTDIR="/mnt/bioinformatics/nextflow_out/2025.06.02_RNAseq_Bulk_T-ALL/rnaseq_quant"
PROJ_OUTDIR="$HOME/github_repos/2025.06.02_RNAseq_Bulk_T-ALL/data/rnaseq_quant"

ln -s $NXF_OUTDIR $PROJ_OUTDIR
```

```{bash}
tmux 
source venv/bin/activate
./main_run.sh 2025.06.02_RNAseq_Bulk_T-ALL_V1
./main_run.sh 2025.06.02_RNAseq_Bulk_T-ALL_V2
```

# Computational Resources

```{bash}
cat reports/2025.06.02_RNAseq_Bulk_T-ALL_V2_2025-07-15.html | grep -E "window.data.+trace" -A 1 > reports/2025.06.02_RNAseq_Bulk_T-ALL_V2_2025-07-15.nextflow_trace.json
```

```{r}
library(jsonlite)

resources <- fromJSON("reports/2025.06.02_RNAseq_Bulk_T-ALL_V2_2025-07-15.nextflow_trace.json")
head(resources)
```

```{r}
resources[resources$task_id == 101, ]
```

```{r}
memory_gb <- R.utils::hsize(sum(as.numeric(resources[["memory"]]), na.rm = TRUE), units = "GB")
memory_gb

cpus <- sum(as.numeric(resources[["cpus"]]), na.rm=TRUE)
cpus
```



# Session Information

```{python}
session_info.show()
```
